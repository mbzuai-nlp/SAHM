<p align="center">
  <img src="docs/assets/logo.png" alt="SAHM Logo" width="200"/>
</p>

<h1 align="center" style="font-size: 42px; font-weight: bold; margin-top: -10px;">
  SAHM
</h1>

<p align="center" style="font-size: 20px; font-style: italic; margin-top: -10px;">
  Arabic Financial Instruction-Tuning Dataset & Models
</p>

<hr style="width: 80%; margin: 30px auto;">

<p align="center">
  <a href="#"><img src="https://img.shields.io/badge/paper-ArXiv-red?style=for-the-badge"></a>
  <a href="https://mbzuai-nlp.github.io/SAHM/"><img src="https://img.shields.io/badge/project-Page-brightgreen?style=for-the-badge"></a>
  <a href="https://mbzuai-nlp.github.io/SAHM/leaderboard.html"><img src="https://img.shields.io/badge/leaderboard-Page-blue?style=for-the-badge"></a>
  <a href="#"><img src="https://img.shields.io/badge/demo-Spaces-gold?style=for-the-badge"></a>
</p>

---

## ğŸŒŸ Overview

**SAHM** is the first **large-scale Arabic financial NLP benchmark** covering both **modern financial analysis** and **Islamic/Shariâ€™ah-compliant reasoning**, introduced in our paper _SAHM: Arabic Financial Instruction-Tuning Dataset And Models_.

It includes **14,000+ high-quality Arabic samples** across **eight tasks**, derived from:

- AAOIFI Shariâ€™ah standards
- Official fatwa archives
- Corporate earnings reports
- Market news
- Business and accounting exams
- Islamic finance regulatory material

SAHM also introduces:  
ğŸŸ¦ **SAHM-7B-Instruct**, an Arabic financial instruction-tuned model  
ğŸŸ¦ A unified evaluation framework  
ğŸŸ¦ First-of-its-kind datasets for Islamic finance + Arabic corporate analysis

---

## ğŸ“Œ Features

Our benchmark includes eight diverse tasks:

1. **Islamic Finance Shariâ€™ah Standards QA**
2. **Islamic Financial Fatwa QA**
3. **Islamic Financial Fatwa MCQ**
4. **Business MCQ**
5. **Accounting MCQ**
6. **Financial Report Sentiment Analysis**
7. **Report Extractive Summarization**
8. **Eventâ€“Cause Reasoning QA**

These tasks reflect **real Arabic financial workflows**, combining modern finance with Islamic jurisprudence (fiqh al-muÊ¿ÄmalÄt).

---

## ğŸ“ Dataset Structure

Each dataset adheres to a unified JSON schema and standardized evaluation protocol.

| Task                     | #Train | #Eval | Format  | Capability                      |
| ------------------------ | ------ | ----- | ------- | ------------------------------- |
| Shariâ€™ah Standards QA    | 1621   | 406   | QA      | Islamic finance legal reasoning |
| Islamic Fatwa QA         | 11,703 | 250   | QA      | Faith-based financial rulings   |
| Eventâ€“Cause Reasoning    | 160    | 40    | QA      | Financial causal inference      |
| Extractive Summarization | 160    | 40    | Summary | Financial disclosure extraction |
| Fatwa MCQ                | â€“      | 250   | MCQ     | Recognition-style reasoning     |
| Business MCQ             | 381    | 76    | MCQ     | Business fundamentals           |
| Accounting MCQ           | 95     | 24    | MCQ     | Numerical & IFRS reasoning      |
| Sentiment Analysis       | 160    | 40    | MCQ     | Financial polarity detection    |

Full details appear in Table 1 of the paper.

---

## ğŸ§  SAHM-7B-Instruct Model

A **7B Arabic-centric model** instruction-tuned on all SAHM datasets.  
Built on top of **ALLAM-7B**, it achieves:

- **Best MCQ performance among Arabic/open models**
- **+37.5 improvement in Accounting MCQ**
- **Strong business & sentiment accuracy**
- Competent but still developing **open-ended reasoning**

See Table 2 in the paper for full comparison.

---

## ğŸ† Leaderboard (MCQ Tasks)

| Model                       | Mean Accuracy (%) |
| --------------------------- | ----------------- |
| **GPT-5**                   | **73.9**          |
| GPT-4o                      | 67.0              |
| Qwen2.5-72B                 | 60.4              |
| Fanar-1-9B                  | 53.9              |
| ALLAM-7B                    | 56.1              |
| **SAHM-7B-Instruct (ours)** | **71.7**          |

---

## ğŸ† Leaderboard (Open-Ended QA)

Average Judge Score (0â€“10):

| Model                | Score    |
| -------------------- | -------- |
| **GPT-5**            | **8.98** |
| Claude 4 Sonnet      | 7.77     |
| GPT-4o               | 7.08     |
| Gemini 2.5 Pro       | 5.73     |
| ALLAM-7B             | 5.05     |
| Fanar-1-9B           | 4.82     |
| **SAHM-7B-Instruct** | **5.07** |

(Open-ended tasks remain significantly harder for current Arabic models.)

---

## ğŸ“ Installation

```bash
git clone https://github.com/mbzuai-nlp/SAHM
cd SAHM
pip install -r requirements.txt
```

## ğŸ’¾ Using the Dataset

```python
from sahm import load_dataset

ds = load_dataset("sahm", "fatwa_qa")
print(ds["train"][0])
```

## ğŸ¤– Using SAHM-7B-Instruct

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

tok = AutoTokenizer.from_pretrained("mbzuai-nlp/SAHM-7B-Instruct")
model = AutoModelForCausalLM.from_pretrained("mbzuai-nlp/SAHM-7B-Instruct")

prompt = "Ø§Ø´Ø±Ø­ Ø­ÙƒÙ… Ø¨ÙŠØ¹ Ø§Ù„Ù…Ø±Ø§Ø¨Ø­Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ØªÙ…Ù„Ùƒ Ø§Ù„Ø³Ù„Ø¹Ø©."
out = model.generate(**tok(prompt, return_tensors="pt"))
print(tok.decode(out[0], skip_special_tokens=True))
```

## ğŸ—‚ Repository Structure

```bash
SAHM/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ shariah_standards/
â”‚   â”œâ”€â”€ fatwa_qa/
â”‚   â”œâ”€â”€ mcq/
â”‚   â”œâ”€â”€ sentiment/
â”‚   â”œâ”€â”€ summarization/
â”‚   â””â”€â”€ event_cause/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ SAHM-7B-Instruct/
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ assets/logo.png
â”‚
â”œâ”€â”€ evaluation/
â””â”€â”€ README.md
```

## ğŸ“˜ Citation

If you use SAHM, please cite:

```bibtex
@article{sahm2025,
  title={SAHM: Arabic Financial Instruction-Tuning Dataset And Models},
  author={Elbadry, Rania and Ahmad, Sarfraz and Bouch, Dani and Ahsan, Momina and Peng, Xueqing and Huang, Jimin and AlMahri, Muhra and Khalil, Marwa Elsaid and Wang, Yuxia and Lahlou, Salem and Stoyanov, Veselin and Ananiadou, Sophia and Nakov, Preslav and Xie, Zhuohan},
  year={2025},
  institution={MBZUAI}
}
```

## ğŸ· License

The dataset and code are released under MIT License
